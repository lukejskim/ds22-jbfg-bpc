{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신러닝 초보를 위한 MNIST ver2 test\n",
    "> [CodeOnWeb](https://codeonweb.com/entry/12045839-0aa9-4bad-8c7e-336b89401e10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 데이터\n",
    ">  \n",
    "- MNIST 데이터는 Yann LeCun의 웹사이트에서 제공합니다. \n",
    "- 편의를 위해 데이터를 자동으로 다운로드하고 설치하는 코드를 포함해 놓았습니다. \n",
    "- 코드를 다운로드 하고 아래와 같이 import하거나, 그냥 안에 붙여 넣으시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist = input_data.read_data_sets(\"./samples/MNIST_data/\", one_hot=True)\n",
    "# ? input_data.read_data_sets(\"./samples/MNIST_data/\", one_hot=True)\n",
    "\n",
    "MNIST_DATA = './data/MNIST_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-e88f8f1b2cbe>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/bigpycraft/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/bigpycraft/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/bigpycraft/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/bigpycraft/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/bigpycraft/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(MNIST_DATA, one_hot=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "다운로드한 데이터는 55000개의 학습 데이터 (mnist.train), 10000개의 테스트 데이터 (mnist.test) 및 5000개의 검증 데이터 (mnist.validation) 세 부분으로 나누어져 있습니다. 이렇게 나눠진 것은 굉장히 중요합니다.\n",
    "\n",
    "손으로 쓴 숫자와 그에 해당하는 라벨입니다. 우리는 이미지를 \"xs\"라고 부르고 라벨을 \"ys\"라고 부르겠습니다. 학습 데이터 세트와 테스트 데이터 세트는 xs와 ys를 포함하고 있습니다. 예를 들어, 학습 세트의 이미지는 mnist.train.images 이며, 학습 세트의 라벨은 mnist.train.labels 입니다.\n",
    "\n",
    "각 이미지는 가로, 세로가 각 28픽셀입니다. 우리는 이걸 숫자로 구성된 큰 행렬로 취급할 수 있습니다:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 소프트맥스 회귀 (Softmax Regressions)\n",
    ">  \n",
    "- 우리는 MNIST의 모든 이미지가 0부터 9까지의 숫자인 것을 알고 있습니다. \n",
    "- 우리는 학습 모델이 이미지를 보았을 때 각 숫자로 판단할 확률을 얻으려고 합니다. \n",
    "- 이 경우는 소프트맥스 회귀가 자연스럽고 간단한 모델인 고전적인 경우입니다. \n",
    "- 만약 어떤 대상이 여러 다양한 것들 중 하나일 확률을 계산하려면 소프트맥스가 가장 적당합니다. 심지어 나중에 우리가 훨씬 더 정교한 모델들을 배웠을 때에도 마지막 단계는 소프트맥스 계층일 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.Variable 초기화\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "* tf.Variable 을 주어서 Variable의 초기값\n",
    "- 이 경우, 우리는 W 와 b 를 0으로 채워진 텐서들로 초기화\n",
    "- W와 b 를 학습할 것이기 때문에, 그것들이 무엇으로 초기화되었는지는 크게 중요하지 않다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구현\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습시키기\n",
    "\n",
    "# 교차엔트로피를 구현하기 위해 우선적으로 정다븡ㄹ 입력하기 위한 새 placeholder를 추가\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차엔트로피\n",
    "cross_entropy =  tf.reduce_mean(y_*tf.log(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 준경사하강법(gradient descent) 알고리즘을 이요앟여 교차엔트로피를 최소화\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행전 마지막으로 변수들을 초기화\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션에서 모델을 시작하고 변수들을 초기화하는 작업을 실행\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 학습 : 1000번\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_:batch_ys})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- 각 반복단계마다, 학습셋으로부터 100개의 무작위 데이터들의 일괄처리들을 가져온다.\n",
    "- placeholders 를 데체하기 위한 일괄 처리 데이터에 train_step 피딩을 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='brown'>비싸거나 저렴한 것은 돈이 아니라 계산에 들어가는 비용을 의미합니다.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가하기\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), \n",
    "                              tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- 우선 맞는 라벨을 예측했는지 확인\n",
    "- tf.argmax는 특정한 축을 따라 가장 큰 원소의 색인을 알려주는 함수\n",
    "- tf.equal을 이용해 예측이 실제와 맞았는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 확인\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1135"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(accuracy, feed_dict={x:mnist.test.images, y_:mnist.test.labels})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- 결과는 약 91%\n",
    "- 이건 좋은걸까요? 음~ 그다지입니다.\n",
    "- 중요한 것은 우리가 이 모델에서 배운 것들입니다. 아직 이 결과들이 조금 쳐지는 느낌이 든다면 더 나은 결과를 얻는 다음 연습을 보고, TensorFlow를 이용해서 어떻게 더 정교한 모델을 만드는지 배워봅시다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추가\n",
    ">  \n",
    "MNIST 예제 샌드박스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Dataset loading\n",
    "mnist = input_data.read_data_sets(MNIST_DATA, one_hot=True)\n",
    "\n",
    "# Set up model\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Learning\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9153\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Result should be approximately 91%.\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=0, \t accuracy=0.11999999731779099, \t cross_entropy=230.25851440429688 \n",
      "step=1, \t accuracy=0.1899999976158142, \t cross_entropy=232.07394409179688 \n",
      "step=2, \t accuracy=0.3499999940395355, \t cross_entropy=423.4611511230469 \n",
      "step=3, \t accuracy=0.3700000047683716, \t cross_entropy=422.7203063964844 \n",
      "step=4, \t accuracy=0.4300000071525574, \t cross_entropy=319.7050476074219 \n",
      "step=100, \t accuracy=0.9300000071525574, \t cross_entropy=31.009479522705078 \n",
      "step=200, \t accuracy=0.8799999952316284, \t cross_entropy=43.67414855957031 \n",
      "step=300, \t accuracy=0.9300000071525574, \t cross_entropy=26.276187896728516 \n",
      "step=400, \t accuracy=0.8999999761581421, \t cross_entropy=35.49628448486328 \n",
      "step=500, \t accuracy=0.949999988079071, \t cross_entropy=22.064958572387695 \n",
      "step=600, \t accuracy=0.8500000238418579, \t cross_entropy=57.71528625488281 \n",
      "step=700, \t accuracy=0.8899999856948853, \t cross_entropy=30.09046173095703 \n",
      "step=800, \t accuracy=0.8899999856948853, \t cross_entropy=31.615114212036133 \n",
      "step=900, \t accuracy=0.9100000262260437, \t cross_entropy=28.109704971313477 \n",
      "step=1000, \t accuracy=0.9100000262260437, \t cross_entropy=22.797523498535156 \n"
     ]
    }
   ],
   "source": [
    "# Session\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Learning\n",
    "for i in range(1001):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    # sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    \n",
    "    t_step, a_val, c_entropy = sess.run([train_step, accuracy, cross_entropy], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "\n",
    "    if i % 100 == 0 or i < 5:\n",
    "        print(\"step={step}, \\t accuracy={accuracy}, \\t cross_entropy={c_entropy} \".format(\n",
    "            step      = i, \n",
    "            accuracy  = a_val,\n",
    "            c_entropy = c_entropy\n",
    "        ));\n",
    "        \n",
    "    # if i % 100 == 0 or i < 5:\n",
    "    #     print(\"step={step}, \\t W={W_val},  \\t b={b_val}, \\t cross_entropy={c_entropy} \".format(\n",
    "    #         step =i, \n",
    "    #         W_val= W_val, \n",
    "    #         b_val=b_val,\n",
    "    #         c_entropy=c_entropy\n",
    "    #     ));\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy 의 의미\n",
    "> https://taeoh-kim.github.io/blog/cross-entropy%EC%9D%98-%EC%A0%95%ED%99%95%ED%95%9C-%ED%99%95%EB%A5%A0%EC%A0%81-%EC%9D%98%EB%AF%B8/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
