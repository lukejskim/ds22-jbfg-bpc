{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab11. CNN (Convolutional Newural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. MNIST CNN Ensemble Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "def chk_processting_time(start_time, end_time):\n",
    "    process_time = end_time - start_time\n",
    "    p_time = int(process_time)\n",
    "    p_min = p_time // 60\n",
    "    p_sec = p_time %  60\n",
    "    print('처리시간 : {p_min}분 {p_sec}초 경과되었습니다.'.format(\n",
    "            p_min = p_min, \n",
    "            p_sec = p_sec\n",
    "        ))\n",
    "    return process_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/user/Dropbox/sect_tech/src_anaconda/B_DL_TensorFlow\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '.')\n",
    "# sys.path.insert(0, '/c/Users/user/Dropbox/sect_tech/src_anaconda/B_DL_TensorFlow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model4.Model Class Load !!\n"
     ]
    }
   ],
   "source": [
    "import model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Lab 11 MNIST and Deep learning CNN\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model4.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Lab 11 MNIST and Deep learning CNN\n",
    "import tensorflow as tf\n",
    "# import matplotlib.pyplot as plt\n",
    "#\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "#\n",
    "# tf.set_random_seed(777)  # reproducibility\n",
    "#\n",
    "# mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "\n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\n",
    "            # for testing\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "\n",
    "            # input place holders\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "            # img 28x28x1 (black/white), Input Layer\n",
    "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "            # Convolutional Layer #1\n",
    "            conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            # Pooling Layer #1\n",
    "            pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            dropout1 = tf.layers.dropout(inputs=pool1,\n",
    "                                         rate=0.7, training=self.training)\n",
    "\n",
    "            # Convolutional Layer #2 and Pooling Layer #2\n",
    "            conv2 = tf.layers.conv2d(inputs=dropout1, filters=64, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            dropout2 = tf.layers.dropout(inputs=pool2,\n",
    "                                         rate=0.7, training=self.training)\n",
    "\n",
    "            # Convolutional Layer #2 and Pooling Layer #2\n",
    "            conv3 = tf.layers.conv2d(inputs=dropout2, filters=128, kernel_size=[3, 3],\n",
    "                                     padding=\"same\", activation=tf.nn.relu)\n",
    "            pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\n",
    "                                            padding=\"same\", strides=2)\n",
    "            dropout3 = tf.layers.dropout(inputs=pool3,\n",
    "                                         rate=0.7, training=self.training)\n",
    "\n",
    "            # Dense Layer with Relu\n",
    "            flat = tf.reshape(dropout3, [-1, 128 * 4 * 4])\n",
    "            dense4 = tf.layers.dense(inputs=flat,\n",
    "                                     units=625, activation=tf.nn.relu)\n",
    "            dropout4 = tf.layers.dropout(inputs=dense4,\n",
    "                                         rate=0.5, training=self.training)\n",
    "\n",
    "            # Logits (no activation) Layer: L5 Final FC 625 inputs -> 10 outputs\n",
    "            self.logits = tf.layers.dense(inputs=dropout4, units=10)\n",
    "\n",
    "        # define cost/loss & optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=learning_rate).minimize(self.cost)\n",
    "\n",
    "        correct_prediction = tf.equal(\n",
    "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, x_test, training=False):\n",
    "        return self.sess.run(self.logits,\n",
    "                             feed_dict={self.X: x_test, self.training: training})\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test, training=False):\n",
    "        return self.sess.run(self.accuracy,\n",
    "                             feed_dict={self.X: x_test,\n",
    "                                        self.Y: y_test, self.training: training})\n",
    "\n",
    "    def train(self, x_data, y_data, training=True):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
    "            self.X: x_data, self.Y: y_data, self.training: training})\n",
    "\n",
    "print('model4.Model Class Load !!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Started!\n",
      "Epoch: 0001 cost = [ 0.82711442  0.78495804] p_time: 281.9383370876312\n",
      "Epoch: 0002 cost = [ 0.2930738   0.29289861] p_time: 558.6102945804596\n",
      "Epoch: 0003 cost = [ 0.22756309  0.23318309] p_time: 820.4461743831635\n",
      "Epoch: 0004 cost = [ 0.19712697  0.19778142] p_time: 1079.0071330070496\n",
      "Epoch: 0005 cost = [ 0.18282352  0.18406503] p_time: 1336.456261396408\n",
      "Epoch: 0006 cost = [ 0.1730285   0.17229101] p_time: 1596.9647433757782\n",
      "Epoch: 0007 cost = [ 0.16330228  0.1589124 ] p_time: 1854.3152043819427\n",
      "Epoch: 0008 cost = [ 0.15629985  0.15698036] p_time: 2123.486513376236\n",
      "Epoch: 0009 cost = [ 0.14847688  0.15527392] p_time: 2389.7255623340607\n",
      "Epoch: 0010 cost = [ 0.14623547  0.14653372] p_time: 2655.4458549022675\n",
      "Epoch: 0011 cost = [ 0.14099916  0.14177114] p_time: 2922.322463274002\n",
      "Epoch: 0012 cost = [ 0.13792419  0.13968794] p_time: 3196.0564863681793\n",
      "Epoch: 0013 cost = [ 0.13552418  0.13554261] p_time: 3472.9366869926453\n",
      "Epoch: 0014 cost = [ 0.13878496  0.14025194] p_time: 3750.3269646167755\n",
      "Epoch: 0015 cost = [ 0.12973776  0.13341517] p_time: 4027.0668182373047\n",
      "Epoch: 0016 cost = [ 0.1320399   0.13005375] p_time: 4305.031638622284\n",
      "Epoch: 0017 cost = [ 0.13102679  0.13220176] p_time: 4579.27229475975\n",
      "Epoch: 0018 cost = [ 0.12794597  0.13386374] p_time: 4853.592389583588\n",
      "Epoch: 0019 cost = [ 0.13328428  0.13004357] p_time: 5127.732130765915\n",
      "Epoch: 0020 cost = [ 0.12148935  0.12644443] p_time: 5408.027544975281\n",
      "Learning Finished!\n",
      "처리시간 : 90분 8초 경과되었습니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5408.038550615311"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 100\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "\n",
    "models = []\n",
    "num_models = 2\n",
    "for m in range(num_models):\n",
    "    models.append(model4.Model(sess, \"model\" + str(m)))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning Started!')\n",
    "time1 = time.time()\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost_list = np.zeros(len(models))\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        # train each model\n",
    "        for m_idx, m in enumerate(models):\n",
    "            c, _ = m.train(batch_xs, batch_ys)\n",
    "            avg_cost_list[m_idx] += c / total_batch\n",
    "  \n",
    "    time2 = time.time()\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', avg_cost_list, 'p_time:', time2-time1)\n",
    "\n",
    "print('Learning Finished!')\n",
    "time2 = time.time()\n",
    "chk_processting_time(time1, time2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Accuracy: 0.9896\n",
      "1 Accuracy: 0.9899\n",
      "Ensemble accuracy: 0.9909\n"
     ]
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "test_size = len(mnist.test.labels)\n",
    "predictions = np.zeros(test_size * 10).reshape(test_size, 10)\n",
    "\n",
    "for m_idx, m in enumerate(models):\n",
    "    print(m_idx, 'Accuracy:', m.get_accuracy(\n",
    "        mnist.test.images, mnist.test.labels))\n",
    "    p = m.predict(mnist.test.images)\n",
    "    predictions += p\n",
    "\n",
    "ensemble_correct_prediction = tf.equal(\n",
    "    tf.argmax(predictions, 1), tf.argmax(mnist.test.labels, 1))\n",
    "ensemble_accuracy = tf.reduce_mean(\n",
    "    tf.cast(ensemble_correct_prediction, tf.float32))\n",
    "print('Ensemble accuracy:', sess.run(ensemble_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 트레이닝 이력 관리?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 784)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m5 = model4.Model(sess, \"m-ensemble\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [9]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlqREhrAkJTKEJSmRISxJif4PZeTSbPZHWT0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x126cec2f940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "# print(\"Prediction: \", m5.predict(mnist.test.images[r:r + 1]))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-32.58203936, -25.06859195,  -6.95515501, ...,  21.72357118,\n",
       "         10.62556708,  12.01700115],\n",
       "       [-12.97484368, -18.73685643,  18.9661901 , ..., -11.78520858,\n",
       "         14.80804634,  -4.86895132],\n",
       "       [-21.7327981 ,  -5.98700571, -10.4400239 , ..., -10.34534538,\n",
       "         16.13064152,   0.68457103],\n",
       "       ..., \n",
       "       [-36.3973012 , -27.03593218, -17.75198293, ...,  -8.36797094,\n",
       "         19.67124054,  10.99340534],\n",
       "       [-16.91331077, -36.91914845, -15.76148343, ..., -21.99358761,\n",
       "         29.86913025,  -2.35699677],\n",
       "       [ -8.3387233 , -36.46751738, -12.51887679, ..., -31.84945834,\n",
       "         18.95994406,  -3.67785215]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = m.predict(mnist.test.images[r:r + 1])\n",
    "predictions += p\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
