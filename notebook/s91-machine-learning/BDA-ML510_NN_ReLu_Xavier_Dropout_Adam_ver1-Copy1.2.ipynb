{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Industry 4.0 의 중심, AI - ML&DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='right'><font size=2 color='gray'>Machine Learning & Deep Learning with TensorFlow @ <font color='blue'><a href='https://www.facebook.com/jskim.kr'>FB / jskim.kr</a></font>, 김진수</font></div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sect10. NN, ReLu, Xavier, Dropout, and Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from images import bigpycraft_ai as bpc\n",
    "from IPython.display import Image \n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import time, os"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<!--\n",
    "### Examples : https://github.com/aymericdamien/TensorFlow-Examples\n",
    "//-->"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<!--\n",
    "import time\n",
    "import os\n",
    "\n",
    "def chk_processting_time(start_time, end_time):\n",
    "    process_time = end_time - start_time\n",
    "    p_time = int(process_time)\n",
    "    p_min = p_time // 60\n",
    "    p_sec = p_time %  60\n",
    "    print('처리시간 : {p_min}분 {p_sec}초 경과되었습니다.'.format(\n",
    "            p_min = p_min, \n",
    "            p_sec = p_sec\n",
    "        ))\n",
    "    return process_time\n",
    "//-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#00AAAA'> \n",
    "# MNIST Dataset Introduction\n",
    "<br>\n",
    "Most examples are using MNIST dataset of handwritten digits. It has 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image, so each sample is represented as a matrix of size 28x28 with values from 0 to 1.\n",
    "\n",
    "### Overview\n",
    "\n",
    "![MNIST Digits](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n",
    "\n",
    "### Usage\n",
    "In our examples, we are using TensorFlow [input_data.py](https://github.com/tensorflow/tensorflow/blob/r0.7/tensorflow/examples/tutorials/mnist/input_data.py) script to load that dataset.\n",
    "It is quite useful for managing our data, and handle:\n",
    "\n",
    "- Dataset downloading\n",
    "\n",
    "- Loading the entire dataset into numpy array: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\python\\anaconda3-1812\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\python\\anaconda3-1812\\lib\\site-packages (from tensorflow) (1.19.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in c:\\python\\anaconda3-1812\\lib\\site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\python\\anaconda3-1812\\lib\\site-packages (from tensorflow) (1.0.7)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\python\\anaconda3-1812\\lib\\site-packages (from tensorflow) (0.32.3)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\python\\anaconda3-1812\\lib\\site-packages (from tensorflow) (3.7.1)\n",
      "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in c:\\python\\anaconda3-1812\\lib\\site-packages (from tensorflow) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\python\\anaconda3-1812\\lib\\site-packages (from tensorflow) (1.15.4)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\python\\anaconda3-1812\\lib\\site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\python\\anaconda3-1812\\lib\\site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\python\\anaconda3-1812\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in c:\\python\\anaconda3-1812\\lib\\site-packages (from tensorflow) (1.13.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\python\\anaconda3-1812\\lib\\site-packages (from tensorflow) (1.0.9)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\python\\anaconda3-1812\\lib\\site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: h5py in c:\\python\\anaconda3-1812\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
      "Requirement already satisfied: setuptools in c:\\python\\anaconda3-1812\\lib\\site-packages (from protobuf>=3.6.1->tensorflow) (40.6.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\python\\anaconda3-1812\\lib\\site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\python\\anaconda3-1812\\lib\\site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: mock>=2.0.0 in c:\\python\\anaconda3-1812\\lib\\site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: pbr>=0.11 in c:\\python\\anaconda3-1812\\lib\\site-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (5.1.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                            Version   \n",
      "---------------------------------- ----------\n",
      "absl-py                            0.7.1     \n",
      "alabaster                          0.7.12    \n",
      "anaconda-client                    1.7.2     \n",
      "anaconda-navigator                 1.9.6     \n",
      "anaconda-project                   0.8.2     \n",
      "asn1crypto                         0.24.0    \n",
      "astor                              0.7.1     \n",
      "astroid                            2.1.0     \n",
      "astropy                            3.1       \n",
      "atomicwrites                       1.2.1     \n",
      "attrs                              18.2.0    \n",
      "Babel                              2.6.0     \n",
      "backcall                           0.1.0     \n",
      "backports.os                       0.1.1     \n",
      "backports.shutil-get-terminal-size 1.0.0     \n",
      "beautifulsoup4                     4.6.3     \n",
      "bitarray                           0.8.3     \n",
      "bkcharts                           0.2       \n",
      "blaze                              0.11.3    \n",
      "bleach                             3.0.2     \n",
      "bokeh                              1.0.2     \n",
      "boto                               2.49.0    \n",
      "Bottleneck                         1.2.1     \n",
      "branca                             0.3.1     \n",
      "certifi                            2018.11.29\n",
      "cffi                               1.11.5    \n",
      "chardet                            3.0.4     \n",
      "Click                              7.0       \n",
      "cloudpickle                        0.6.1     \n",
      "clyent                             1.2.2     \n",
      "colorama                           0.4.1     \n",
      "comtypes                           1.1.7     \n",
      "conda                              4.5.12    \n",
      "conda-build                        3.17.6    \n",
      "conda-verify                       3.1.1     \n",
      "contextlib2                        0.5.5     \n",
      "cryptography                       2.4.2     \n",
      "cycler                             0.10.0    \n",
      "Cython                             0.29.2    \n",
      "cytoolz                            0.9.0.1   \n",
      "dask                               1.0.0     \n",
      "datashape                          0.5.4     \n",
      "decorator                          4.3.0     \n",
      "defusedxml                         0.5.0     \n",
      "distributed                        1.25.1    \n",
      "docutils                           0.14      \n",
      "entrypoints                        0.2.3     \n",
      "et-xmlfile                         1.0.1     \n",
      "fastcache                          1.0.2     \n",
      "filelock                           3.0.10    \n",
      "Flask                              1.0.2     \n",
      "Flask-Cors                         3.0.7     \n",
      "folium                             0.8.3     \n",
      "future                             0.17.1    \n",
      "gast                               0.2.2     \n",
      "gevent                             1.3.7     \n",
      "glob2                              0.6       \n",
      "greenlet                           0.4.15    \n",
      "grpcio                             1.19.0    \n",
      "h5py                               2.8.0     \n",
      "heapdict                           1.0.0     \n",
      "html5lib                           1.0.1     \n",
      "idna                               2.8       \n",
      "imageio                            2.4.1     \n",
      "imagesize                          1.1.0     \n",
      "importlib-metadata                 0.6       \n",
      "ipykernel                          5.1.0     \n",
      "ipython                            7.2.0     \n",
      "ipython-genutils                   0.2.0     \n",
      "ipywidgets                         7.4.2     \n",
      "isort                              4.3.4     \n",
      "itsdangerous                       1.1.0     \n",
      "jdcal                              1.4       \n",
      "jedi                               0.13.2    \n",
      "Jinja2                             2.10      \n",
      "JPype1                             0.7.0     \n",
      "jsonschema                         2.6.0     \n",
      "jupyter                            1.0.0     \n",
      "jupyter-client                     5.2.4     \n",
      "jupyter-console                    6.0.0     \n",
      "jupyter-core                       4.4.0     \n",
      "jupyterlab                         0.35.3    \n",
      "jupyterlab-server                  0.2.0     \n",
      "Keras-Applications                 1.0.7     \n",
      "Keras-Preprocessing                1.0.9     \n",
      "keyring                            17.0.0    \n",
      "kiwisolver                         1.0.1     \n",
      "konlpy                             0.5.1     \n",
      "lazy-object-proxy                  1.3.1     \n",
      "libarchive-c                       2.8       \n",
      "llvmlite                           0.26.0    \n",
      "locket                             0.2.0     \n",
      "lxml                               4.2.5     \n",
      "Markdown                           3.1       \n",
      "MarkupSafe                         1.1.0     \n",
      "matplotlib                         3.0.2     \n",
      "mccabe                             0.6.1     \n",
      "menuinst                           1.4.14    \n",
      "missingno                          0.4.2     \n",
      "mistune                            0.8.4     \n",
      "mkl-fft                            1.0.6     \n",
      "mkl-random                         1.0.2     \n",
      "mock                               2.0.0     \n",
      "more-itertools                     4.3.0     \n",
      "mpmath                             1.1.0     \n",
      "msgpack                            0.5.6     \n",
      "multipledispatch                   0.6.0     \n",
      "navigator-updater                  0.2.1     \n",
      "nbconvert                          5.4.0     \n",
      "nbformat                           4.4.0     \n",
      "networkx                           2.2       \n",
      "nltk                               3.4       \n",
      "nose                               1.3.7     \n",
      "notebook                           5.7.4     \n",
      "numba                              0.41.0    \n",
      "numexpr                            2.6.8     \n",
      "numpy                              1.15.4    \n",
      "numpydoc                           0.8.0     \n",
      "odo                                0.5.1     \n",
      "olefile                            0.46      \n",
      "openpyxl                           2.5.12    \n",
      "packaging                          18.0      \n",
      "pandas                             0.23.4    \n",
      "pandocfilters                      1.4.2     \n",
      "parso                              0.3.1     \n",
      "partd                              0.3.9     \n",
      "path.py                            11.5.0    \n",
      "pathlib2                           2.3.3     \n",
      "patsy                              0.5.1     \n",
      "pbr                                5.1.3     \n",
      "pep8                               1.7.1     \n",
      "pickleshare                        0.7.5     \n",
      "Pillow                             5.3.0     \n",
      "pip                                18.1      \n",
      "pkginfo                            1.4.2     \n",
      "pluggy                             0.8.0     \n",
      "ply                                3.11      \n",
      "prometheus-client                  0.5.0     \n",
      "prompt-toolkit                     2.0.7     \n",
      "protobuf                           3.7.1     \n",
      "psutil                             5.4.8     \n",
      "py                                 1.7.0     \n",
      "pycodestyle                        2.4.0     \n",
      "pycosat                            0.6.3     \n",
      "pycparser                          2.19      \n",
      "pycrypto                           2.6.1     \n",
      "pycurl                             7.43.0.2  \n",
      "pyflakes                           2.0.0     \n",
      "pygame                             1.9.6     \n",
      "Pygments                           2.3.1     \n",
      "pylint                             2.2.2     \n",
      "pyodbc                             4.0.25    \n",
      "pyOpenSSL                          18.0.0    \n",
      "pyparsing                          2.3.0     \n",
      "PyQt5                              5.12.1    \n",
      "PyQt5-sip                          4.19.15   \n",
      "PySocks                            1.6.8     \n",
      "pytagcloud                         0.3.5     \n",
      "pytest                             4.0.2     \n",
      "pytest-arraydiff                   0.3       \n",
      "pytest-astropy                     0.5.0     \n",
      "pytest-doctestplus                 0.2.0     \n",
      "pytest-openfiles                   0.3.1     \n",
      "pytest-remotedata                  0.3.1     \n",
      "python-dateutil                    2.7.5     \n",
      "pytz                               2018.7    \n",
      "PyWavelets                         1.0.1     \n",
      "pywin32                            223       \n",
      "pywinpty                           0.5.5     \n",
      "PyYAML                             3.13      \n",
      "pyzmq                              17.1.2    \n",
      "QtAwesome                          0.5.3     \n",
      "qtconsole                          4.4.3     \n",
      "QtPy                               1.5.2     \n",
      "requests                           2.21.0    \n",
      "rope                               0.11.0    \n",
      "ruamel-yaml                        0.15.46   \n",
      "scikit-image                       0.14.1    \n",
      "scikit-learn                       0.20.1    \n",
      "scipy                              1.1.0     \n",
      "seaborn                            0.9.0     \n",
      "selenium                           3.141.0   \n",
      "Send2Trash                         1.5.0     \n",
      "setuptools                         40.6.3    \n",
      "simplegeneric                      0.8.1     \n",
      "simplejson                         3.16.0    \n",
      "singledispatch                     3.4.0.3   \n",
      "six                                1.12.0    \n",
      "snowballstemmer                    1.2.1     \n",
      "sortedcollections                  1.0.1     \n",
      "sortedcontainers                   2.1.0     \n",
      "Sphinx                             1.8.2     \n",
      "sphinxcontrib-websupport           1.1.0     \n",
      "spyder                             3.3.2     \n",
      "spyder-kernels                     0.3.0     \n",
      "SQLAlchemy                         1.2.15    \n",
      "statsmodels                        0.9.0     \n",
      "sympy                              1.3       \n",
      "tables                             3.4.4     \n",
      "tblib                              1.3.2     \n",
      "tensorboard                        1.13.1    \n",
      "tensorflow                         1.13.1    \n",
      "tensorflow-estimator               1.13.0    \n",
      "termcolor                          1.1.0     \n",
      "terminado                          0.8.1     \n",
      "testpath                           0.4.2     \n",
      "toolz                              0.9.0     \n",
      "tornado                            5.1.1     \n",
      "tqdm                               4.28.1    \n",
      "traitlets                          4.3.2     \n",
      "unicodecsv                         0.14.1    \n",
      "urllib3                            1.24.1    \n",
      "wcwidth                            0.1.7     \n",
      "webencodings                       0.5.1     \n",
      "Werkzeug                           0.14.1    \n",
      "wheel                              0.32.3    \n",
      "widgetsnbextension                 3.4.2     \n",
      "win-inet-pton                      1.0.1     \n",
      "win-unicode-console                0.5       \n",
      "wincertstore                       0.2       \n",
      "wordcloud                          1.5.0     \n",
      "wrapt                              1.10.11   \n",
      "xlrd                               1.2.0     \n",
      "XlsxWriter                         1.1.2     \n",
      "xlwings                            0.15.1    \n",
      "xlwt                               1.3.0     \n",
      "zict                               0.1.3     \n"
     ]
    }
   ],
   "source": [
    "! pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow.examples.tutorials.mnist.input_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement tensorflow.examples.tutorials.mnist.input_data (from versions: )\n",
      "No matching distribution found for tensorflow.examples.tutorials.mnist.input_data\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow.examples.tutorials.mnist.input_data\n",
    "# from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.core._multiarray_umath'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy.core._multiarray_umath'"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<class '_frozen_importlib._ModuleLockManager'> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Python\\Anaconda3-1812\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: <class '_frozen_importlib._ModuleLockManager'> returned a result with an error set"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core._multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core._multiarray_umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.umath failed to import"
     ]
    }
   ],
   "source": [
    "# from tensorflow.examples.tutorials.mnist \n",
    "import tensorflow.examples.tutorials.mnist.input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.core._multiarray_umath'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy.core._multiarray_umath'"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<class '_frozen_importlib._ModuleLockManager'> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Python\\Anaconda3-1812\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: <class '_frozen_importlib._ModuleLockManager'> returned a result with an error set"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core._multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core._multiarray_umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.umath failed to import"
     ]
    }
   ],
   "source": [
    "# Import MNIST\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\", one_hot=True)\n",
    "\n",
    "# Load data\n",
    "X_train = mnist.train.images\n",
    "Y_train = mnist.train.labels\n",
    "X_test = mnist.test.images\n",
    "Y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#00CCCC'> \n",
    "- A \"next_batch\" function that can iterate over the whole dataset and return only the desired fraction of the dataset samples (in order to save memory and avoid to load the entire dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the next 64 images array and labels\n",
    "batch_X, batch_Y = mnist.train.next_batch(64)\n",
    "batch_X, batch_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "def chk_processting_time(start_time, end_time):\n",
    "    process_time = end_time - start_time\n",
    "    p_time = int(process_time)\n",
    "    p_min = p_time // 60\n",
    "    p_sec = p_time %  60\n",
    "    print('처리시간 : {p_min}분 {p_sec}초 경과되었습니다.'.format(\n",
    "            p_min = p_min, \n",
    "            p_sec = p_sec\n",
    "        ))\n",
    "    return process_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "time.sleep(3)\n",
    "time2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_processting_time(time1, time2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### 1. Softmax classifier for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review : Learning rate and Evaluation\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# input place holders, 784(=28*28)\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# weights & bias for nn layers\n",
    "W = tf.Variable(tf.random_normal([784, 10]))\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Signature: tf.reduce_mean(input_tensor, axis=None, keep_dims=False, name=None, reduction_indices=None)\n",
    "Docstring:\n",
    "Computes the mean of elements across dimensions of a tensor.\n",
    "\n",
    "Args:\n",
    "  input_tensor: The tensor to reduce. Should have numeric type.\n",
    "  axis: The dimensions to reduce. If `None` (the default), reduces all dimensions.\n",
    "  keep_dims: If true, retains reduced dimensions with length 1.\n",
    "  name: A name for the operation (optional).\n",
    "  reduction_indices: The old (deprecated) name for axis.\n",
    "\n",
    "Returns:\n",
    "  The reduced tensor."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Signature: tf.nn.softmax_cross_entropy_with_logits(_sentinel=None, labels=None, logits=None, dim=-1, name=None)\n",
    "Docstring:\n",
    "Computes softmax cross entropy between `logits` and `labels`.\n",
    "\n",
    "Args:\n",
    "  _sentinel: Used to prevent positional parameters. Internal, do not use.\n",
    "  labels: Each row `labels[i]` must be a valid probability distribution.\n",
    "  logits: Unscaled log probabilities.\n",
    "  dim: The class dimension. Defaulted to -1 which is the last dimension.\n",
    "  name: A name for the operation (optional).\n",
    "\n",
    "Returns:\n",
    "  A 1-D `Tensor` of length `batch_size` of the same type as `logits` with the\n",
    "  softmax cross entropy loss."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Init signature: tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, use_locking=False, name='Adam')\n",
    "Docstring:     \n",
    "Optimizer that implements the Adam algorithm.\n",
    "\n",
    "Args:\n",
    "  learning_rate: A Tensor or a floating point value.  The learning rate.\n",
    "  beta1: A float value or a constant float tensor.\n",
    "         The exponential decay rate for the 1st moment estimates.\n",
    "  beta2: A float value or a constant float tensor.\n",
    "         The exponential decay rate for the 2nd moment estimates.\n",
    "  epsilon: A small constant for numerical stability.\n",
    "  use_locking: If True use locks for update operations.\n",
    "  name: Optional name for the operations created when applying gradients.\n",
    "        Defaults to \"Adam\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "time1 = time.time()\n",
    "for epoch in tqdm_notebook(range(training_epochs)):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), ' | cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "time2 = time.time()\n",
    "\n",
    "bpc.chk_processting_time(time1, time2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training_epochs, mnist.train.num_examples, total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### 2. NN(Newral Nets) for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST and NN\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# weights & bias for nn layers\n",
    "# W1 = tf.Variable(tf.random_normal([784, 256]))\n",
    "# b1 = tf.Variable(tf.random_normal([256]))\n",
    "# L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "# W2 = tf.Variable(tf.random_normal([256, 256]))\n",
    "# b2 = tf.Variable(tf.random_normal([256]))\n",
    "# L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "# W3 = tf.Variable(tf.random_normal([256, 10]))\n",
    "# b3 = tf.Variable(tf.random_normal([10]))\n",
    "# hypothesis = tf.matmul(L2, W3) + b3\n",
    "\n",
    "# tf Graph input\n",
    "W1 = tf.Variable(tf.random_normal([784, 256]))\n",
    "W2 = tf.Variable(tf.random_normal([256, 256]))\n",
    "W3 = tf.Variable(tf.random_normal([256, 10]))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "hypothesis = tf.matmul(L2, W3) + b3\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "# Softmax loss\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))     \n",
    "\n",
    "# Adam Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "time1 = time.time()\n",
    "for epoch in tqdm_notebook(range(training_epochs)):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), ' | cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "time2 = time.time()\n",
    "\n",
    "bpc.chk_processting_time(time1, time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs, mnist.train.num_examples, total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr>\n",
    "\n",
    "### 3. Xavier initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 방법 : initializer=tf.contrib.layers.xavier_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 10 MNIST and Xavier\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# weights & bias for nn layers\n",
    "# http://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 256],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[256, 256],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[256, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L2, W3) + b3\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "time1 = time.time()\n",
    "for epoch in tqdm_notebook(range(training_epochs)):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), ' | cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "time2 = time.time()\n",
    "\n",
    "bpc.chk_processting_time(time1, time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr>\n",
    "<marquee><font size=3 color='brown'>The BigpyCraft find the information to design valuable society with Technology & Craft.</font></marquee>\n",
    "<div align='right'><font size=2 color='gray'> &lt; The End &gt; </font></div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
