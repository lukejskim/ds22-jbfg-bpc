{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Industry 4.0 의 중심, BigData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='right'><font size=2 color='gray'>Data Processing Based Python @ <font color='blue'><a href='https://www.facebook.com/jskim.kr'>FB / jskim.kr</a></font>, [김진수](bigpycraft@gmail.com)</font></div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='brown'>웹 스크레이핑을 위한 기본 지식 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML의 기본 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir htmltest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./htmltest/HTML_example.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./htmltest/HTML_example.html \n",
    "<!doctype html>\n",
    "<html>\n",
    " <head>\n",
    "  <meta charset=\"utf-8\">\n",
    "  <title>이것은 HTML 예제</title>\n",
    " </head>\n",
    " <body>\n",
    "  <h1>출간된 책 정보</h1>\n",
    "  <p id=\"book_title\">이해가 쏙쏙 되는 파이썬</p>\n",
    "  <p id=\"author\">홍길동</p>\n",
    "  <p id=\"publisher\">위키북스 출판사</p>\n",
    "  <p id=\"year\">2018</p>\n",
    " </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./htmltest/HTML_example2.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./htmltest/HTML_example2.html \n",
    "<!doctype html>\n",
    "<html>\n",
    " <head>\n",
    "  <meta charset=\"utf-8\">\n",
    "  <title>이것은 HTML 예제</title>\n",
    " </head>\n",
    " <body>\n",
    "  <h1>출간된 책 정보</h1>\n",
    "  <p>이해가 쏙쏙 되는 파이썬</p>\n",
    "  <p>홍길동</p>\n",
    "  <p>위키북스 출판사</p>\n",
    "  <p>2018</p>\n",
    " </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웹 페이지의 HTML 소스 갖고 오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "res = requests.get(\"https://www.google.co.kr\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html><html itemscope=\"\" itemtype=\"http://schema.org/WebPage\" lang=\"ko\"><head><meta content=\"text/html; charset=UTF-8\" http-equiv=\"Content-Type\"><meta content=\"/images/branding/googleg/1x/googleg_standard_color_128dp.png\" itemprop=\"image\"><title>Google</title><script nonce=\"BQtSMZrbIn9nEr4z'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.text[0:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html><html itemscope=\"\" itemtype=\"http://schema.org/WebPage\" lang=\"ko\"><head><meta content=\"text/html; charset=UTF-8\" http-equiv=\"Content-Type\"><meta content=\"/images/branding/googleg/1x/googleg_standard_color_128dp.png\" itemprop=\"image\"><title>Google</title><script nonce=\"yR9SHg9SdUvqK6Ok'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "html = requests.get(\"https://www.google.co.kr\").text\n",
    "html[0:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(requests.models.Response, str)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res), type(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML 소스코드를 분석하고 처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 찾고 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body><div><span>\n",
       "<a href=\"http://www.naver.com\">naver</a>\n",
       "<a href=\"https://www.google.com\">google</a>\n",
       "<a href=\"http://www.daum.net/\">daum</a>\n",
       "</span></div></body></html>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 테스트용 html 코드\n",
    "html = \"\"\"\n",
    "<html><body><div><span>\n",
    "<a href=http://www.naver.com>naver</a>\n",
    "<a href=https://www.google.com>google</a>\n",
    "<a href=http://www.daum.net/>daum</a>\n",
    "</span></div></body></html>\n",
    "\"\"\" \n",
    "\n",
    "# BeautifulSoup를 이용해 HTML 소스를 파싱\n",
    "soup = BeautifulSoup(html, 'lxml') \n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <div>\n",
      "   <span>\n",
      "    <a href=\"http://www.naver.com\">\n",
      "     naver\n",
      "    </a>\n",
      "    <a href=\"https://www.google.com\">\n",
      "     google\n",
      "    </a>\n",
      "    <a href=\"http://www.daum.net/\">\n",
      "     daum\n",
      "    </a>\n",
      "   </span>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"http://www.naver.com\">naver</a>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'naver'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('a').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"http://www.naver.com\">naver</a>,\n",
       " <a href=\"https://www.google.com\">google</a>,\n",
       " <a href=\"http://www.daum.net/\">daum</a>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naver\n",
      "google\n",
      "daum\n"
     ]
    }
   ],
   "source": [
    "site_names = soup.find_all('a')\n",
    "for site_name in site_names:\n",
    "    print(site_name.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 테스트용 HTML 코드\n",
    "html2 = \"\"\"\n",
    "<html>\n",
    " <head>\n",
    "  <title>작품과 작가 모음</title>\n",
    " </head>\n",
    " <body>\n",
    "  <h1>책 정보</h1>\n",
    "  <p class=\"book_title\">토지</p>\n",
    "  <p class=\"author\">박경리</p>\n",
    "  \n",
    "  <p class=\"book_title\">태백산맥</p>\n",
    "  <p class=\"author\">조정래</p>\n",
    "\n",
    "  <p class=\"book_title\">감옥으로부터의 사색</p>\n",
    "  <p class=\"author\">신영복</p>\n",
    " </body>\n",
    "</html>\n",
    "\"\"\" \n",
    "\n",
    "soup2 = BeautifulSoup(html2, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>작품과 작가 모음</title>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body>\n",
       "<h1>책 정보</h1>\n",
       "<p class=\"book_title\">토지</p>\n",
       "<p class=\"author\">박경리</p>\n",
       "<p class=\"book_title\">태백산맥</p>\n",
       "<p class=\"author\">조정래</p>\n",
       "<p class=\"book_title\">감옥으로부터의 사색</p>\n",
       "<p class=\"author\">신영복</p>\n",
       "</body>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>책 정보</h1>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.body.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"book_title\">토지</p>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.body.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"book_title\">토지</p>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.find('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"book_title\">토지</p>,\n",
       " <p class=\"author\">박경리</p>,\n",
       " <p class=\"book_title\">태백산맥</p>,\n",
       " <p class=\"author\">조정래</p>,\n",
       " <p class=\"book_title\">감옥으로부터의 사색</p>,\n",
       " <p class=\"author\">신영복</p>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"book_title\">토지</p>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.find('p', 'book_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"author\">박경리</p>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.find('p', 'author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"book_title\">토지</p>,\n",
       " <p class=\"book_title\">태백산맥</p>,\n",
       " <p class=\"book_title\">감옥으로부터의 사색</p>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.find_all('p', 'book_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"author\">박경리</p>,\n",
       " <p class=\"author\">조정래</p>,\n",
       " <p class=\"author\">신영복</p>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.find_all('p', 'author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 토지 / 박경리 \n",
      " - 태백산맥 / 조정래 \n",
      " - 감옥으로부터의 사색 / 신영복 \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup2 = BeautifulSoup(html2, \"lxml\")\n",
    "\n",
    "book_titles = soup2.find_all('p', 'book_title')\n",
    "authors     = soup2.find_all('p', 'author')\n",
    "\n",
    "for book_title, author in zip(book_titles, authors):\n",
    "    print(' - {} / {} '.format(book_title.get_text(), author.get_text()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='brown'>웹 사이트에서 데이터 가져오기 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순위 데이터를 가져오기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 웹 사이트 순위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests  \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "url = \"https://www.alexa.com/topsites/countries/KR\"\n",
    "\n",
    "html_website_ranking = requests.get(url).text\n",
    "soup_website_ranking = BeautifulSoup(html_website_ranking, \"lxml\")\n",
    "\n",
    "# p 태그의 요소 안에서 a 태그의 요소를 찾음\n",
    "website_ranking = soup_website_ranking.select('p a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking = soup_website_ranking.find_all('div')\n",
    "len(website_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking = soup_website_ranking.find_all('div', 'tr site-listing')\n",
    "len(website_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"tr site-listing\">\n",
       "<div class=\"td number\">1</div>\n",
       "<div class=\"td DescriptionCell\">\n",
       "<p class=\"\">\n",
       "<a href=\"/siteinfo/naver.com\">Naver.com</a>\n",
       "</p>\n",
       "<div class=\"description\">\n",
       " <span class=\"remainder\"></span>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"td right\"><p>14:11</p></div>\n",
       "<div class=\"td right\"><p>8.46</p></div>\n",
       "<div class=\"td right\"><p>9.00%</p></div>\n",
       "<div class=\"td right\"><p>75,421</p></div>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = website_ranking[0]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"td number\">1</div>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp1 = tmp.find('div', 'td number')\n",
    "tmp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"/siteinfo/naver.com\">Naver.com</a>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp2 = tmp.find('a')\n",
    "tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = tmp1.get_text()\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Naver.com'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site = tmp2.get_text()\n",
    "site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/siteinfo/naver.com'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = tmp2['href']\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Top Sites in South Korea]\n",
      "--------------------------------------------------\n",
      "1위. Naver.com (/siteinfo/naver.com)\n",
      "2위. Youtube.com (/siteinfo/youtube.com)\n",
      "3위. Google.co.kr (/siteinfo/google.co.kr)\n",
      "4위. Google.com (/siteinfo/google.com)\n",
      "5위. Daum.net (/siteinfo/daum.net)\n",
      "6위. Tistory.com (/siteinfo/tistory.com)\n",
      "7위. Namu.wiki (/siteinfo/namu.wiki)\n",
      "8위. Facebook.com (/siteinfo/facebook.com)\n",
      "9위. Dcinside.com (/siteinfo/dcinside.com)\n",
      "10위. Wikipedia.org (/siteinfo/wikipedia.org)\n",
      "11위. Gmarket.co.kr (/siteinfo/gmarket.co.kr)\n",
      "12위. Twitter.com (/siteinfo/twitter.com)\n",
      "13위. Ruliweb.com (/siteinfo/ruliweb.com)\n",
      "14위. Blog.me (/siteinfo/blog.me)\n",
      "15위. Instagram.com (/siteinfo/instagram.com)\n",
      "16위. Twitch.tv (/siteinfo/twitch.tv)\n",
      "17위. 11st.co.kr (/siteinfo/11st.co.kr)\n",
      "18위. Auction.co.kr (/siteinfo/auction.co.kr)\n",
      "19위. Baidu.com (/siteinfo/baidu.com)\n",
      "20위. Inven.co.kr (/siteinfo/inven.co.kr)\n",
      "21위. Donga.com (/siteinfo/donga.com)\n",
      "22위. Qq.com (/siteinfo/qq.com)\n",
      "23위. Tmall.com (/siteinfo/tmall.com)\n",
      "24위. Amazon.com (/siteinfo/amazon.com)\n",
      "25위. Taobao.com (/siteinfo/taobao.com)\n",
      "26위. Marumaru.in (/siteinfo/marumaru.in)\n",
      "27위. Kakao.com (/siteinfo/kakao.com)\n",
      "28위. Torrenthaja.com (/siteinfo/torrenthaja.com)\n",
      "29위. Coupang.com (/siteinfo/coupang.com)\n",
      "30위. T.co (/siteinfo/t.co)\n",
      "31위. Afreecatv.com (/siteinfo/afreecatv.com)\n",
      "32위. Wasabisyrup.com (/siteinfo/wasabisyrup.com)\n",
      "33위. Nate.com (/siteinfo/nate.com)\n",
      "34위. Etoland.co.kr (/siteinfo/etoland.co.kr)\n",
      "35위. Netflix.com (/siteinfo/netflix.com)\n",
      "36위. Clien.net (/siteinfo/clien.net)\n",
      "37위. Nicovideo.jp (/siteinfo/nicovideo.jp)\n",
      "38위. Danawa.com (/siteinfo/danawa.com)\n",
      "39위. Interpark.com (/siteinfo/interpark.com)\n",
      "40위. Sohu.com (/siteinfo/sohu.com)\n",
      "41위. Ilbe.com (/siteinfo/ilbe.com)\n",
      "42위. Blogspot.com (/siteinfo/blogspot.com)\n",
      "43위. Microsoft.com (/siteinfo/microsoft.com)\n",
      "44위. Tumblr.com (/siteinfo/tumblr.com)\n",
      "45위. Apple.com (/siteinfo/apple.com)\n",
      "46위. Torrentmap.com (/siteinfo/torrentmap.com)\n",
      "47위. Nexon.com (/siteinfo/nexon.com)\n",
      "48위. Wemakeprice.com (/siteinfo/wemakeprice.com)\n",
      "49위. Aliexpress.com (/siteinfo/aliexpress.com)\n",
      "50위. Joins.com (/siteinfo/joins.com)\n"
     ]
    }
   ],
   "source": [
    "Rank = []\n",
    "Site = []\n",
    "Link = []\n",
    "\n",
    "print(\"[Top Sites in South Korea]\")\n",
    "print(\"-\"*50)\n",
    "for idx in range(len(website_ranking)):\n",
    "    tmp = website_ranking[idx]\n",
    "    tmp1 = tmp.find('div', 'td number')\n",
    "    tmp2 = tmp.find('a')\n",
    "    rank = tmp1.get_text()\n",
    "    site = tmp2.get_text()\n",
    "    link = tmp2['href']\n",
    "    \n",
    "    print(\"{}위. {} ({})\".format(rank, site, link))\n",
    "    \n",
    "    Rank.append(rank)\n",
    "    Site.append(site)\n",
    "    Link.append(link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4', '5']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rank[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Naver.com', 'Youtube.com', 'Google.co.kr', 'Google.com', 'Daum.net']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Site[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/siteinfo/naver.com',\n",
       " '/siteinfo/youtube.com',\n",
       " '/siteinfo/google.co.kr',\n",
       " '/siteinfo/google.com',\n",
       " '/siteinfo/daum.net']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Link[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Rank':Rank, 'Site':Site, 'Link':Link}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/siteinfo/naver.com</td>\n",
       "      <td>1</td>\n",
       "      <td>Naver.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/siteinfo/youtube.com</td>\n",
       "      <td>2</td>\n",
       "      <td>Youtube.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/siteinfo/google.co.kr</td>\n",
       "      <td>3</td>\n",
       "      <td>Google.co.kr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/siteinfo/google.com</td>\n",
       "      <td>4</td>\n",
       "      <td>Google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/siteinfo/daum.net</td>\n",
       "      <td>5</td>\n",
       "      <td>Daum.net</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Link Rank          Site\n",
       "0     /siteinfo/naver.com    1     Naver.com\n",
       "1   /siteinfo/youtube.com    2   Youtube.com\n",
       "2  /siteinfo/google.co.kr    3  Google.co.kr\n",
       "3    /siteinfo/google.com    4    Google.com\n",
       "4      /siteinfo/daum.net    5      Daum.net"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Site</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/siteinfo/naver.com</td>\n",
       "      <td>Naver.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/siteinfo/youtube.com</td>\n",
       "      <td>Youtube.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/siteinfo/google.co.kr</td>\n",
       "      <td>Google.co.kr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/siteinfo/google.com</td>\n",
       "      <td>Google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/siteinfo/daum.net</td>\n",
       "      <td>Daum.net</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Link          Site\n",
       "Rank                                      \n",
       "1        /siteinfo/naver.com     Naver.com\n",
       "2      /siteinfo/youtube.com   Youtube.com\n",
       "3     /siteinfo/google.co.kr  Google.co.kr\n",
       "4       /siteinfo/google.com    Google.com\n",
       "5         /siteinfo/daum.net      Daum.net"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index('Rank', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 주간 음악 순위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"ellipsis\">너를 만나</span>,\n",
       " <span class=\"ellipsis\">삐삐</span>,\n",
       " <span class=\"ellipsis\">가을 타나 봐</span>,\n",
       " <span class=\"ellipsis\">하루도 그대를 사랑하지 않은 적이 없었다</span>,\n",
       " <span class=\"ellipsis\">모든 날, 모든 순간 (Every day, Every Moment)</span>,\n",
       " <span class=\"ellipsis\">멋지게 인사하는 법 (Feat. 슬기 of Red Velvet)</span>,\n",
       " <span class=\"ellipsis\">Good Day (Feat. 팔로알토) (Prod. 코드 쿤스트)</span>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://music.naver.com/listen/history/index.nhn?type=TOTAL&year=2018&month=11&week=1\"\n",
    "html_music = requests.get(url).text\n",
    "soup_music = BeautifulSoup(html_music, \"lxml\")\n",
    "\n",
    "# a 태그의 요소 중에서 class 속성값이 \"_title\" 인 것을 찾고\n",
    "# 그 안에서 span 태그의 요소 중에서 class 속성값이 \"ellipsis\"인 요소를 추출\n",
    "titles = soup_music.select('a._title span.ellipsis') \n",
    "titles[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "music_titles = [title.get_text() for title in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['너를 만나',\n",
       " '삐삐',\n",
       " '가을 타나 봐',\n",
       " '하루도 그대를 사랑하지 않은 적이 없었다',\n",
       " '모든 날, 모든 순간 (Every day, Every Moment)',\n",
       " '멋지게 인사하는 법 (Feat. 슬기 of Red Velvet)',\n",
       " 'Good Day (Feat. 팔로알토) (Prod. 코드 쿤스트)']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_titles[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\r\\n\\t\\t\\t\\r\\n\\t\\t\\t\\r\\n\\t\\t\\t폴킴\\r\\n\\t\\t'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a 태그의 요소 중에서 class 속성값이 \"_artist\" 인 것을 찾고\n",
    "# 그 안에서 span 태그의 요소 중에서 class 속성값이 \"ellipsis\"인 요소를 추출\n",
    "artists = soup_music.select('a._artist span.ellipsis') \n",
    "artists[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'폴킴'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[0].get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "music_artists = [artist.get_text().strip() for artist in artists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['폴킴', '아이유(IU)', '바이브', '임창정', '폴킴', 'Zion.T', '루피(Loopy)']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_artists[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# td 태그의 요소 중에서 class 속성값이 \"_artist\" 인 것을 찾고\n",
    "# 그 안에서 a 태그의 요소를 추출\n",
    "artists = soup_music.select('td._artist a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"_artist NPI=a:artist,r:1,i:383616\" href=\"/artist/home.nhn?artistId=383616\" title=\"폴킴\">\n",
       "<span class=\"ellipsis\">\n",
       "\t\t\t\n",
       "\t\t\t\n",
       "\t\t\t폴킴\n",
       "\t\t</span>\n",
       "</a>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"_artist NPI=a:artist,r:5,i:383616\" href=\"/artist/home.nhn?artistId=383616\" title=\"폴킴\">\n",
       "<span class=\"ellipsis\">\n",
       "\t\t\t\n",
       "\t\t\t\n",
       "\t\t\t폴킴\n",
       "\t\t</span>\n",
       "</a>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'폴킴'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[0].get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'폴킴'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[4].get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "music_artists = [artist.get_text().strip() for artist in artists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['폴킴', '아이유(IU)', '바이브', '임창정', '폴킴', 'Zion.T', 'pH-1']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_artists[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 너를 만나 / 폴킴\n",
      "2: 삐삐 / 아이유(IU)\n",
      "3: 가을 타나 봐 / 바이브\n",
      "4: 하루도 그대를 사랑하지 않은 적이 없었다 / 임창정\n",
      "5: 모든 날, 모든 순간 (Every day, Every Moment) / 폴킴\n",
      "6: 멋지게 인사하는 법 (Feat. 슬기 of Red Velvet) / Zion.T\n",
      "7: Good Day (Feat. 팔로알토) (Prod. 코드 쿤스트) / pH-1\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    " \n",
    "url = 'https://music.naver.com/listen/history/index.nhn?type=DOMESTIC&year=2018&month=11&week=1&page=1'\n",
    "# url = \"https://music.naver.com/listen/history/index.nhn?type=DOMESTIC&year=2018&month=12&week=1&page=2\"\n",
    "# url = \"http://music.naver.com/listen/top100.nhn?domain=TOTAL&page=1\"\n",
    "    \n",
    "html_music = requests.get(url).text\n",
    "soup_music = BeautifulSoup(html_music, \"lxml\")\n",
    "\n",
    "titles = soup_music.select('a._title span.ellipsis') \n",
    "artists = soup_music.select('td._artist a')\n",
    "\n",
    "music_titles = [title.get_text() for title in titles]\n",
    "music_artists = [artist.get_text().strip() for artist in artists]\n",
    "\n",
    "for k in range(7):\n",
    "    print(\"{0}: {1} / {2}\".format(k+1, music_titles[k], music_artists[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "music_titles_artists={}\n",
    "order = 0\n",
    "\n",
    "for (music_title, music_artist) in zip(music_titles, music_artists):\n",
    "    order = order + 1\n",
    "    music_titles_artists[order] = [music_title, music_artist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['너를 만나', '폴킴']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_titles_artists[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['삐삐', '아이유(IU)']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_titles_artists[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./htmltest/NaverMusicTop100.txt']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import glob\n",
    "    \n",
    "naver_music_url = \"http://music.naver.com/listen/history/index.nhn?type=DOMESTIC&year=2017&month=12&week=1&page=\"\n",
    " \n",
    "# 네이버 music 주소를 입력하면 노래 제목과 아티스트를 반환\n",
    "def naver_music(url):    \n",
    "    html_music = requests.get(url).text\n",
    "    soup_music = BeautifulSoup(html_music, \"lxml\")\n",
    "\n",
    "    titles = soup_music.select('a._title span.ellipsis') \n",
    "    artists = soup_music.select('td._artist a')\n",
    "\n",
    "    music_titles = [title.get_text() for title in titles]\n",
    "    music_artists = [artist.get_text().strip() for artist in artists]\n",
    "    \n",
    "    return music_titles, music_artists\n",
    "\n",
    "# 노래 제목과 아티스트를 저장할 파일 이름을 폴더와 함께 지정\n",
    "file_name = './htmltest/NaverMusicTop100.txt'\n",
    "\n",
    "f = open(file_name,'w') # 파일 열기\n",
    "\n",
    "# 각 page에는 50개의 노래 제목과 아티스트가 추출됨\n",
    "for page in range(2):\n",
    "    naver_music_url_page = naver_music_url + str(page+1) # page URL\n",
    "    nave_music_titles, naver_music_artists = naver_music(naver_music_url_page)\n",
    "    \n",
    "    # 추출된 노래 제목과 아티스트를 파일에 저장 \n",
    "    for k in range(len(music_titles_artists)):\n",
    "        f.write(\"{0:2d}: {1}/{2}\\n\".format(page*50 + k+1, nave_music_titles[k],  naver_music_artists[k]))\n",
    "\n",
    "f.close() # 파일 닫기\n",
    "\n",
    "glob.glob(file_name) # 생성된 파일 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웹 페이지에서 이미지 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하나의 이미지 내려받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests  \n",
    "\n",
    "url = 'https://www.python.org/static/img/python-logo.png'\n",
    "html_image = requests.get(url)\n",
    "html_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python-logo.png'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_file_name = os.path.basename(url)\n",
    "image_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = './htmltest/download' \n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./htmltest/download\\\\python-logo.png'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = os.path.join(folder, image_file_name)\n",
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imageFile = open(image_path, 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 이미지 데이터를 100000 바이트씩 나눠서 내려받고 파일에 순차적으로 저장\n",
    "chunk_size = 1000000\n",
    "for chunk in html_image.iter_content(chunk_size):\n",
    "    imageFile.write(chunk)\n",
    "imageFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python-logo.png']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests  \n",
    "import os\n",
    "\n",
    "url = 'https://www.python.org/static/img/python-logo.png'\n",
    "image_file_name = os.path.basename(url)\n",
    "\n",
    "folder = './htmltest/download' \n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "image_path = os.path.join(folder, image_file_name)\n",
    "\n",
    "imageFile = open(image_path, 'wb')\n",
    "# 이미지 데이터를 100000 바이트씩 나눠서 저장\n",
    "chunk_size = 1000000\n",
    "for chunk in html_image.iter_content(chunk_size):\n",
    "    imageFile.write(chunk)\n",
    "imageFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 여러 이미지 내려받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<img alt=\"꿀벌 먹는 사람, 색상, 새 들, 지점, 가까운, 국\" src=\"https://cdn.pixabay.com/photo/2018/10/15/18/32/bee-eaters-3749679__340.jpg\" srcset=\"https://cdn.pixabay.com/photo/2018/10/15/18/32/bee-eaters-3749679__340.jpg 1x, https://cdn.pixabay.com/photo/2018/10/15/18/32/bee-eaters-3749679__480.jpg 2x\"/>,\n",
       " <img alt=\"자연, 태양, 구름, 동물, 새, 왜라기, 나는, 일몰, 해돋이, 배너\" src=\"https://cdn.pixabay.com/photo/2018/11/01/14/37/nature-3788312__340.jpg\" srcset=\"https://cdn.pixabay.com/photo/2018/11/01/14/37/nature-3788312__340.jpg 1x, https://cdn.pixabay.com/photo/2018/11/01/14/37/nature-3788312__480.jpg 2x\"/>,\n",
       " <img alt=\"염소, 염소 보모, 동물, 포유 동물, 반추 동물, 머리, 뿔, 귀, 눈\" src=\"https://cdn.pixabay.com/photo/2018/11/02/11/07/goat-3790060__340.jpg\" srcset=\"https://cdn.pixabay.com/photo/2018/11/02/11/07/goat-3790060__340.jpg 1x, https://cdn.pixabay.com/photo/2018/11/02/11/07/goat-3790060__480.jpg 2x\"/>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests  \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "URL = 'https://pixabay.com/ko/photos/?order=popular&cat=animals'\n",
    "\n",
    "html_pixabay_image = requests.get(URL).text\n",
    "soup_pixabay_image = BeautifulSoup(html_pixabay_image, \"lxml\")\n",
    "pixabay_image_elements = soup_pixabay_image.select('img') \n",
    "pixabay_image_elements[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://cdn.pixabay.com/photo/2018/10/15/18/32/bee-eaters-3749679__340.jpg'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixabay_image_url = pixabay_image_elements[0].get('src')\n",
    "pixabay_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html_image = requests.get(pixabay_image_url)\n",
    "\n",
    "folder = \"./htmltest/download\"\n",
    "    \n",
    "# os.path.basename(URL)는 웹사이트나 폴더가 포함된 파일명에서 파일명만 분리하는 방법    \n",
    "imageFile = open(os.path.join(folder, os.path.basename(pixabay_image_url)), 'wb')\n",
    "\n",
    "# 이미지 데이터를 100000 바이트씩 나눠서 저장하는 방법\n",
    "chunk_size = 1000000 \n",
    "for chunk in html_image.iter_content(chunk_size):\n",
    "    imageFile.write(chunk)\n",
    "imageFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 파일명: 'bee-eaters-3749679__340.jpg'. 내려받기 완료!\n",
      "이미지 파일명: 'nature-3788312__340.jpg'. 내려받기 완료!\n",
      "이미지 파일명: 'goat-3790060__340.jpg'. 내려받기 완료!\n",
      "이미지 파일명: 'kuhnase-3777407__340.jpg'. 내려받기 완료!\n",
      "이미지 파일명: 'canada-goose-3788091__340.jpg'. 내려받기 완료!\n",
      "이미지 파일명: 'tiger-3784924__340.jpg'. 내려받기 완료!\n",
      "이미지 파일명: 'animal-3786987__340.jpg'. 내려받기 완료!\n",
      "================================\n",
      "선택한 모든 이미지 내려받기 완료!\n"
     ]
    }
   ],
   "source": [
    "import requests  \n",
    "from bs4 import BeautifulSoup \n",
    "import os\n",
    "\n",
    "# URL(주소)에서 이미지 주소 추출\n",
    "def get_image_url(url): \n",
    "    html_image_url = requests.get(url).text\n",
    "    soup_image_url = BeautifulSoup(html_image_url, \"lxml\")  \n",
    "    image_elements = soup_image_url.select('img') \n",
    "    if(image_elements != None):\n",
    "        image_urls = []\n",
    "        for image_element in image_elements:\n",
    "            image_urls.append(image_element.get('src'))\n",
    "        return image_urls        \n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# 폴더를 지정해 이미지 주소에서 이미지 내려받기\n",
    "def download_image(img_folder, img_url):\n",
    "    if(img_url != None):  \n",
    "        html_image = requests.get(img_url)\n",
    "        # os.path.basename(URL)는 웹사이트나 폴더가 포함된 파일명에서 파일명만 분리    \n",
    "        imageFile = open(os.path.join(img_folder, os.path.basename(img_url)), 'wb')\n",
    "\n",
    "        chunk_size = 1000000 # 이미지 데이터를 100000 바이트씩 나눠서 저장\n",
    "        for chunk in html_image.iter_content(chunk_size):\n",
    "            imageFile.write(chunk)\n",
    "            imageFile.close()\n",
    "        print(\"이미지 파일명: '{0}'. 내려받기 완료!\".format(os.path.basename(img_url))) \n",
    "    else:       \n",
    "        print(\"내려받을 이미지가 없습니다.\")\n",
    "        \n",
    "# 웹 사이트의 주소 지정   \n",
    "pixabay_url = 'https://pixabay.com/ko/photos/?order=popular&cat=animals'\n",
    "# pixabay_url= 'https://pixabay.com/ko/photos/?order=popular&cat=animals&pagi=2'\n",
    "\n",
    "figure_folder = \"./htmltest/download\" # 이미지를 내려받을 폴더 지정  \n",
    "\n",
    "pixabay_image_urls = get_image_url(pixabay_url) # 이미지 파일의 주소 가져오기\n",
    "\n",
    "num_of_download_image = 7 # 내려받을 이미지 개수 지정\n",
    "# num_of_download_image = len(pixabay_image_urls)\n",
    "\n",
    "for k in range(num_of_download_image):\n",
    "    download_image(figure_folder,pixabay_image_urls[k])\n",
    "print(\"================================\")\n",
    "print(\"선택한 모든 이미지 내려받기 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_download_image = len(pixabay_image_urls)\n",
    "num_of_download_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<marquee><font size=3 color='brown'>The BigpyCraft find the information to design valuable society with Technology & Craft.</font></marquee>\n",
    "<div align='right'><font size=2 color='gray'> &lt; The End &gt; </font></div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nav_menu": {},
  "toc": {
   "nav_menu": {
    "height": "400px",
    "width": "252px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "545px",
    "left": "0px",
    "right": "1154px",
    "top": "111px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "toc_position": {
   "height": "503px",
   "left": "0px",
   "right": "952.167px",
   "top": "107px",
   "width": "300px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
